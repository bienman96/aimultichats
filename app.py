"""
Multi-AI Debate Tool v3
=======================
ëª¨ë“œë³„ AI í† ë¡  ì‹œìŠ¤í…œ

AI êµ¬ì„±:
- ì›¹ì†Œì„¤: GPT, Gemini (2ëª…)
- ê²Œì„ê°œë°œ: Claude, Gemini (2ëª…)  
- ì¼ë°˜í† ë¡ : GPT, Claude, Gemini (3ëª…)

ê¸°ëŠ¥:
- ì—¬ëŸ¬ ì±„íŒ…ë°© ê´€ë¦¬
- AI ì§€ì • í˜¸ì¶œ (í´ë¡œë“œ:, ì§€í”¼í‹°:, ì œë¯¸ë‚˜ì´:)
- <<í™•ì •>>, <<ê²°ë¡ >>ìœ¼ë¡œ í† ë¡  ê²°ê³¼ ì €ì¥
"""

import streamlit as st
import os
import json
from datetime import datetime
from pathlib import Path
from openai import OpenAI
import anthropic
import google.generativeai as genai

# =============================================================================
# ì„¤ì •
# =============================================================================

def get_api_key(key_name: str) -> str:
    """Streamlit secrets -> í™˜ê²½ë³€ìˆ˜ ìˆœì„œë¡œ API í‚¤ ë¡œë“œ"""
    try:
        if key_name in st.secrets:
            return st.secrets[key_name]
    except:
        pass
    return os.getenv(key_name, "")

OPENAI_API_KEY = get_api_key("OPENAI_API_KEY")
ANTHROPIC_API_KEY = get_api_key("ANTHROPIC_API_KEY")
GOOGLE_API_KEY = get_api_key("GOOGLE_API_KEY")

GPT_MODEL = "gpt-4.1"
CLAUDE_MODEL = "claude-sonnet-4-20250514"
GEMINI_MODEL = "gemini-2.5-pro-preview-06-05"

openai_client = None
anthropic_client = None

if OPENAI_API_KEY:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
if ANTHROPIC_API_KEY:
    anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

DATA_DIR = Path("chat_data")
DATA_DIR.mkdir(exist_ok=True)

def check_api_keys():
    missing = []
    if not OPENAI_API_KEY:
        missing.append("OPENAI_API_KEY")
    if not ANTHROPIC_API_KEY:
        missing.append("ANTHROPIC_API_KEY")
    if not GOOGLE_API_KEY:
        missing.append("GOOGLE_API_KEY")
    return missing

# =============================================================================
# ì±„íŒ…ë°© ê´€ë¦¬
# =============================================================================

def get_chat_list():
    chats = []
    if DATA_DIR.exists():
        for f in DATA_DIR.glob("*.json"):
            try:
                with open(f, "r", encoding="utf-8") as file:
                    data = json.load(file)
                    chats.append({
                        "id": f.stem,
                        "name": data.get("name", f.stem),
                        "mode": data.get("mode", "ì¼ë°˜í† ë¡ "),
                        "updated": data.get("updated", "")
                    })
            except:
                pass
    chats.sort(key=lambda x: x.get("updated", ""), reverse=True)
    return chats

def load_chat(chat_id):
    filepath = DATA_DIR / f"{chat_id}.json"
    if filepath.exists():
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def save_chat(chat_id, data):
    data["updated"] = datetime.now().isoformat()
    filepath = DATA_DIR / f"{chat_id}.json"
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def create_new_chat(name, mode):
    chat_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    data = {
        "id": chat_id, "name": name, "mode": mode,
        "created": datetime.now().isoformat(),
        "updated": datetime.now().isoformat(),
        "system_prompt": get_default_system_prompt(mode),
        "messages": [], "debate_history": [], "conclusions": []
    }
    save_chat(chat_id, data)
    return chat_id

def delete_chat(chat_id):
    filepath = DATA_DIR / f"{chat_id}.json"
    if filepath.exists():
        filepath.unlink()

def get_default_system_prompt(mode):
    if mode == "ì›¹ì†Œì„¤":
        return """ë‹¹ì‹ ì€ í•œêµ­ ì›¹ì†Œì„¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì¸ê³µì˜ ë‹¨ê³„ì  ì„±ì¥ê³¼ ë…ìì—ê²Œ ì£¼ëŠ” ê¸°ëŒ€ê°/ëŒ€ë¦¬ë§Œì¡±ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.
í”Œë¡¯, ìºë¦­í„°, ì„±ì¥ ì„¤ê³„, ëª…ì¥ë©´ êµ¬ì„±ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ì˜ê²¬ì„ ì œì‹œí•©ë‹ˆë‹¤."""
    elif mode == "ê²Œì„ê°œë°œ":
        return """ë‹¹ì‹ ì€ ê²Œì„ ê°œë°œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„, ì½”ë“œ êµ¬í˜„, ìµœì í™”ì— ëŒ€í•´ ì „ë¬¸ì ì¸ ì˜ê²¬ì„ ì œì‹œí•©ë‹ˆë‹¤.
GameMaker Studio 2 (GML), Godot (GDScript), Python ë“±ì— ëŠ¥ìˆ™í•©ë‹ˆë‹¤.
ì½”ë“œëŠ” ë°˜ë“œì‹œ ```gml, ```python, ```gdscript ë“± ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì„œ ì¶œë ¥í•˜ì„¸ìš”."""
    else:
        return """ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” í† ë¡ ì´ ê°€ëŠ¥í•œ AIì…ë‹ˆë‹¤."""

# =============================================================================
# AI í˜¸ì¶œ
# =============================================================================

def call_gpt(messages, system_prompt=""):
    if not openai_client:
        return "[GPT ì˜¤ë¥˜] API í‚¤ ì—†ìŒ"
    try:
        full_messages = []
        if system_prompt:
            full_messages.append({"role": "system", "content": system_prompt})
        full_messages.extend(messages)
        response = openai_client.chat.completions.create(
            model=GPT_MODEL, messages=full_messages, max_tokens=4000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[GPT ì˜¤ë¥˜] {str(e)}"

def call_claude(messages, system_prompt=""):
    if not anthropic_client:
        return "[Claude ì˜¤ë¥˜] API í‚¤ ì—†ìŒ"
    try:
        response = anthropic_client.messages.create(
            model=CLAUDE_MODEL, max_tokens=4000,
            system=system_prompt if system_prompt else "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AIì…ë‹ˆë‹¤.",
            messages=messages
        )
        return response.content[0].text
    except Exception as e:
        return f"[Claude ì˜¤ë¥˜] {str(e)}"

def call_gemini(prompt, context=""):
    if not GOOGLE_API_KEY:
        return "[Gemini ì˜¤ë¥˜] API í‚¤ ì—†ìŒ"
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        full_prompt = f"{context}\n\n{prompt}" if context else prompt
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"[Gemini ì˜¤ë¥˜] {str(e)}"

# =============================================================================
# í† ë¡  ë¡œì§
# =============================================================================

def build_context_from_history(history, max_turns=20):
    recent = history[-max_turns:] if len(history) > max_turns else history
    parts = []
    for msg in recent:
        ai_name = msg.get("ai_name", "")
        content = msg.get("content", "")
        if ai_name:
            parts.append(f"[{ai_name}]: {content}")
        else:
            parts.append(f"[ì‚¬ìš©ì]: {content}")
    return "\n".join(parts)

def build_messages_for_api(history, max_turns=20):
    recent = history[-max_turns:] if len(history) > max_turns else history
    messages = []
    for msg in recent:
        role = msg.get("role", "user")
        content = msg.get("content", "")
        ai_name = msg.get("ai_name", "")
        if role == "user":
            messages.append({"role": "user", "content": content})
        else:
            prefix = f"[{ai_name}] " if ai_name else ""
            messages.append({"role": "assistant", "content": f"{prefix}{content}"})
    return messages

def parse_target_ai(user_input):
    prefixes = {
        "í´ë¡œë“œ:": "Claude", "claude:": "Claude", "Claude:": "Claude",
        "ì§€í”¼í‹°:": "GPT", "gpt:": "GPT", "GPT:": "GPT", "ì±—ì§€í”¼í‹°:": "GPT",
        "ì œë¯¸ë‚˜ì´:": "Gemini", "gemini:": "Gemini", "Gemini:": "Gemini", "ì œë¯¸ë‹ˆ:": "Gemini",
    }
    for prefix, ai_name in prefixes.items():
        if user_input.strip().startswith(prefix):
            return ai_name, user_input.strip()[len(prefix):].strip()
    return None, user_input

def check_conclusion_trigger(text):
    triggers = ["<<í™•ì •>>", "<<ê²°ë¡ >>", "<<ì €ì¥>>", "<<ì •ë¦¬>>"]
    return any(t in text for t in triggers)

def get_available_ais(mode):
    if mode == "ì›¹ì†Œì„¤":
        return ["GPT", "Gemini"]
    elif mode == "ê²Œì„ê°œë°œ":
        return ["Claude", "Gemini"]
    else:
        return ["GPT", "Claude", "Gemini"]

def run_debate_round(user_message, history, system_prompt, mode, target_ai=None):
    responses = []
    context = build_context_from_history(history)
    messages = build_messages_for_api(history)
    
    current_messages = messages + [{"role": "user", "content": user_message}]
    current_context = context + f"\n[ì‚¬ìš©ì]: {user_message}"
    
    available_ais = get_available_ais(mode)
    ai_list_str = ", ".join(available_ais)
    
    debate_system = system_prompt + f"""

ë‹¹ì‹ ì€ {len(available_ais)}ëª…ì˜ AI({ai_list_str})ê°€ í•¨ê»˜ í† ë¡ í•˜ëŠ” ì„¸ì…˜ì— ì°¸ì—¬ì¤‘ì…ë‹ˆë‹¤.
ë‹¤ë¥¸ AIë“¤ì˜ ì˜ê²¬ì„ ì°¸ê³ í•˜ë˜, ë‹¹ì‹ ë§Œì˜ ê´€ì ì„ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.
ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‹µë³€ì„ í•˜ì„¸ìš”.
"""
    
    if target_ai:
        if target_ai == "GPT":
            resp = call_gpt(current_messages, debate_system)
            responses.append(("GPT", resp))
        elif target_ai == "Claude":
            resp = call_claude(current_messages, debate_system)
            responses.append(("Claude", resp))
        elif target_ai == "Gemini":
            resp = call_gemini(user_message, current_context + "\n\n" + debate_system)
            responses.append(("Gemini", resp))
    else:
        accumulated_context = current_context
        accumulated_messages = current_messages
        
        for i, ai_name in enumerate(available_ais):
            if i == 0:
                if ai_name == "GPT":
                    resp = call_gpt(accumulated_messages, debate_system)
                elif ai_name == "Claude":
                    resp = call_claude(accumulated_messages, debate_system)
                elif ai_name == "Gemini":
                    resp = call_gemini(user_message, accumulated_context + "\n\n" + debate_system)
            else:
                prev_responses = "\n".join([f"- {n}: {r[:800]}" for n, r in responses])
                enhanced_system = debate_system + f"\n\nì§€ê¸ˆê¹Œì§€ì˜ í† ë¡ :\n{prev_responses}\n\nì´ì— ëŒ€í•´ ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ì œì‹œí•˜ì„¸ìš”."
                
                if ai_name == "GPT":
                    resp = call_gpt(accumulated_messages, enhanced_system)
                elif ai_name == "Claude":
                    resp = call_claude(accumulated_messages, enhanced_system)
                elif ai_name == "Gemini":
                    gemini_prompt = f"ì´ì „ í† ë¡ :\n{accumulated_context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
                    resp = call_gemini(gemini_prompt, debate_system)
            
            responses.append((ai_name, resp))
            accumulated_context += f"\n[{ai_name}]: {resp}"
            accumulated_messages.append({"role": "assistant", "content": f"[{ai_name}] {resp}"})
    
    return responses

# =============================================================================
# Streamlit UI
# =============================================================================

st.set_page_config(page_title="Multi-AI Debate", page_icon="ğŸ¤–", layout="wide")

if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None
if "show_new_chat_form" not in st.session_state:
    st.session_state.show_new_chat_form = False

# API í‚¤ í™•ì¸
missing_keys = check_api_keys()
if missing_keys:
    st.error(f"âš ï¸ API í‚¤ ëˆ„ë½: {', '.join(missing_keys)}")
    with st.expander("ğŸ”‘ API í‚¤ ì„¤ì • ë°©ë²•", expanded=True):
        st.markdown("""
`.streamlit/secrets.toml` íŒŒì¼ ìƒì„±:
```toml
OPENAI_API_KEY = "sk-..."
ANTHROPIC_API_KEY = "sk-ant-..."
GOOGLE_API_KEY = "AIza..."
```
        """)
    st.stop()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ’¬ ì±„íŒ…ë°©")
    
    if st.button("â• ìƒˆ ì±„íŒ… ì‹œì‘", use_container_width=True, type="primary"):
        st.session_state.show_new_chat_form = True
    
    if st.session_state.show_new_chat_form:
        with st.form("new_chat_form"):
            st.subheader("ìƒˆ ì±„íŒ…ë°©")
            new_name = st.text_input("ì´ë¦„", placeholder="ì˜ˆ: ê±°ë¶ì„  ê²Œì„")
            new_mode = st.selectbox("ëª¨ë“œ", ["ì›¹ì†Œì„¤", "ê²Œì„ê°œë°œ", "ì¼ë°˜í† ë¡ "])
            mode_ais = {"ì›¹ì†Œì„¤": "GPT, Gemini", "ê²Œì„ê°œë°œ": "Claude, Gemini", "ì¼ë°˜í† ë¡ ": "GPT, Claude, Gemini"}
            st.caption(f"ì°¸ì—¬ AI: {mode_ais[new_mode]}")
            
            c1, c2 = st.columns(2)
            with c1:
                if st.form_submit_button("ë§Œë“¤ê¸°", use_container_width=True):
                    if new_name.strip():
                        new_id = create_new_chat(new_name.strip(), new_mode)
                        st.session_state.current_chat_id = new_id
                        st.session_state.show_new_chat_form = False
                        st.rerun()
            with c2:
                if st.form_submit_button("ì·¨ì†Œ", use_container_width=True):
                    st.session_state.show_new_chat_form = False
                    st.rerun()
    
    st.divider()
    
    for chat in get_chat_list():
        icon = {"ì›¹ì†Œì„¤": "ğŸ“–", "ê²Œì„ê°œë°œ": "ğŸ®", "ì¼ë°˜í† ë¡ ": "ğŸ’­"}.get(chat["mode"], "ğŸ’¬")
        c1, c2 = st.columns([5, 1])
        with c1:
            is_active = st.session_state.current_chat_id == chat["id"]
            if st.button(f"{icon} {chat['name']}", key=f"c_{chat['id']}", 
                        use_container_width=True, type="primary" if is_active else "secondary"):
                st.session_state.current_chat_id = chat["id"]
                st.rerun()
        with c2:
            if st.button("ğŸ—‘ï¸", key=f"d_{chat['id']}"):
                delete_chat(chat["id"])
                if st.session_state.current_chat_id == chat["id"]:
                    st.session_state.current_chat_id = None
                st.rerun()
    
    st.divider()
    with st.expander("ğŸ¤– ëª¨ë“œë³„ AI"):
        st.markdown("| ëª¨ë“œ | AI |\n|---|---|\n| ğŸ“–ì›¹ì†Œì„¤ | GPT, Gemini |\n| ğŸ®ê²Œì„ | Claude, Gemini |\n| ğŸ’­í† ë¡  | ì „ì› |")

# ë©”ì¸
if st.session_state.current_chat_id:
    chat_data = load_chat(st.session_state.current_chat_id)
    
    if chat_data:
        mode = chat_data["mode"]
        available_ais = get_available_ais(mode)
        icon = {"ì›¹ì†Œì„¤": "ğŸ“–", "ê²Œì„ê°œë°œ": "ğŸ®", "ì¼ë°˜í† ë¡ ": "ğŸ’­"}.get(mode, "ğŸ’¬")
        
        c1, c2 = st.columns([4, 1])
        with c1:
            st.title(f"{icon} {chat_data['name']}")
            st.caption(f"AI: {', '.join(available_ais)}")
        with c2:
            if st.button("ğŸ”„ ì´ˆê¸°í™”"):
                chat_data["messages"] = []
                chat_data["debate_history"] = []
                save_chat(st.session_state.current_chat_id, chat_data)
                st.rerun()
        
        with st.expander("âš™ï¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"):
            new_sys = st.text_area("", chat_data.get("system_prompt", ""), height=120)
            if st.button("ì €ì¥"):
                chat_data["system_prompt"] = new_sys
                save_chat(st.session_state.current_chat_id, chat_data)
                st.success("ì €ì¥ë¨!")
        
        with st.expander("ğŸ“ ì°¸ì¡° íŒŒì¼"):
            uploaded = st.file_uploader("íŒŒì¼", type=["txt", "md", "py", "gml", "json", "gd"])
            ref_content = ""
            if uploaded:
                ref_content = uploaded.read().decode("utf-8")
                st.success(f"ë¡œë“œ: {uploaded.name}")
        
        if chat_data.get("conclusions"):
            with st.expander(f"ğŸ“‹ ê²°ë¡  ({len(chat_data['conclusions'])}ê°œ)"):
                for i, con in enumerate(chat_data["conclusions"]):
                    st.markdown(f"**{i+1}.** {con.get('timestamp', '')}")
                    st.info(con.get("content", ""))
        
        st.divider()
        
        for msg in chat_data.get("messages", []):
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.write(msg["content"])
            else:
                ai = msg.get("ai_name", "AI")
                av = {"GPT": "ğŸŸ¢", "Claude": "ğŸŸ ", "Gemini": "ğŸ”µ", "System": "ğŸ’¾"}.get(ai, "ğŸ¤–")
                with st.chat_message("assistant", avatar=av):
                    st.markdown(f"**[{ai}]**")
                    st.write(msg["content"])
        
        if user_input := st.chat_input("ì…ë ¥... (ì§€ì •: í´ë¡œë“œ:, ì§€í”¼í‹°:, ì œë¯¸ë‚˜ì´: / ì €ì¥: <<í™•ì •>>)"):
            full_sys = chat_data.get("system_prompt", "")
            if ref_content:
                full_sys += f"\n\n[ì°¸ì¡°]\n{ref_content}"
            
            if check_conclusion_trigger(user_input):
                with st.chat_message("user"):
                    st.write(user_input)
                chat_data["messages"].append({"role": "user", "content": user_input})
                
                summary_prompt = f"í† ë¡  ì •ë¦¬:\n{build_context_from_history(chat_data.get('debate_history', []))}\n\nì§€ì‹œ: {user_input}"
                
                with st.spinner("ê²°ë¡  ì •ë¦¬..."):
                    if mode == "ê²Œì„ê°œë°œ":
                        conclusion = call_claude([{"role": "user", "content": summary_prompt}], "í† ë¡  ì •ë¦¬ ì „ë¬¸ê°€")
                    else:
                        conclusion = call_gpt([{"role": "user", "content": summary_prompt}], "í† ë¡  ì •ë¦¬ ì „ë¬¸ê°€")
                
                chat_data.setdefault("conclusions", []).append({
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
                    "content": conclusion
                })
                chat_data["messages"].append({"role": "assistant", "ai_name": "System", "content": f"ğŸ“‹ ê²°ë¡  ì €ì¥ë¨\n\n{conclusion}"})
                save_chat(st.session_state.current_chat_id, chat_data)
                
                with st.chat_message("assistant", avatar="ğŸ’¾"):
                    st.success(conclusion)
            else:
                target, actual = parse_target_ai(user_input)
                with st.chat_message("user"):
                    st.write(user_input)
                
                chat_data["messages"].append({"role": "user", "content": user_input})
                chat_data["debate_history"].append({"role": "user", "content": actual})
                
                spinner = f"{target} ë‹µë³€ ì¤‘..." if target else f"í† ë¡  ì¤‘... ({', '.join(available_ais)})"
                with st.spinner(spinner):
                    responses = run_debate_round(actual, chat_data.get("debate_history", []), full_sys, mode, target)
                
                av_map = {"GPT": "ğŸŸ¢", "Claude": "ğŸŸ ", "Gemini": "ğŸ”µ"}
                for ai, resp in responses:
                    with st.chat_message("assistant", avatar=av_map.get(ai, "ğŸ¤–")):
                        st.markdown(f"**[{ai}]**")
                        st.write(resp)
                    chat_data["messages"].append({"role": "assistant", "ai_name": ai, "content": resp})
                    chat_data["debate_history"].append({"role": "assistant", "ai_name": ai, "content": resp})
                
                save_chat(st.session_state.current_chat_id, chat_data)
            st.rerun()

else:
    st.title("ğŸ¤– Multi-AI Debate Tool v3")
    st.markdown("""
### ëª¨ë“œë³„ AI êµ¬ì„±
| ëª¨ë“œ | AI | ìš©ë„ |
|---|---|---|
| ğŸ“– ì›¹ì†Œì„¤ | GPT, Gemini | í”Œë¡¯, ì„±ì¥ ì„¤ê³„ |
| ğŸ® ê²Œì„ê°œë°œ | Claude, Gemini | ì•Œê³ ë¦¬ì¦˜, ì½”ë”© |
| ğŸ’­ ì¼ë°˜í† ë¡  | GPT, Claude, Gemini | ë²”ìš© |

### ì‚¬ìš©ë²•
- **ê·¸ëƒ¥ ì…ë ¥**: ëª¨ë“œë³„ AI ì „ì› í† ë¡ 
- **`í´ë¡œë“œ:`, `ì§€í”¼í‹°:`, `ì œë¯¸ë‚˜ì´:`**: í•´ë‹¹ AIë§Œ
- **`<<í™•ì •>>`**: ê²°ë¡  ì €ì¥
    """)
    
    st.divider()
    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("ğŸ“– ì›¹ì†Œì„¤\n(GPT, Gemini)", use_container_width=True):
            st.session_state.current_chat_id = create_new_chat("ìƒˆ ì›¹ì†Œì„¤", "ì›¹ì†Œì„¤")
            st.rerun()
    with c2:
        if st.button("ğŸ® ê²Œì„ê°œë°œ\n(Claude, Gemini)", use_container_width=True):
            st.session_state.current_chat_id = create_new_chat("ìƒˆ ê²Œì„", "ê²Œì„ê°œë°œ")
            st.rerun()
    with c3:
        if st.button("ğŸ’­ ì¼ë°˜í† ë¡ \n(ì „ì›)", use_container_width=True):
            st.session_state.current_chat_id = create_new_chat("ìƒˆ í† ë¡ ", "ì¼ë°˜í† ë¡ ")
            st.rerun()
